# MetaGPT Configuration Example

# LLM settings
llm:
  api_type: "openai"  # Supported: openai, azure, anthropic, ollama, groq, deepseek, qianfan, zhipuai, etc
  model: "gpt-4-turbo"  # Recommended: gpt-4-turbo or gpt-3.5-turbo for OpenAI
  base_url: "https://api.openai.com/v1"  # Change to your API endpoint if using a proxy
  api_key: "your-api-key-here"  # Replace with your actual API key
  
  # Azure-specific settings (only needed if api_type is "azure")
  # azure_api_version: "2023-05-15"
  # azure_deployment_name: "your-deployment-name"

# File storage settings
storage:
  root_path: "./"

# Recovery settings
recover:
  auto_recover: false  # Whether to recover from previous session automatically
  recovery_file: "recovery.json"  # File to store recovery data
  max_steps_in_context: 4  # Maximum number of steps to keep in context

# Project settings
project:
  name: "My MetaGPT Project"
  desc: "A project generated by MetaGPT"
  
# Agent settings
agent:
  async_mode: false
  use_reflection: true
  use_compression: true
  
# Code execution settings (optional)
execution:
  allow_code_execution: false  # Whether to allow code execution
  execution_mode: "local"  # local or docker

# Logging settings
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  
# HTTP Proxy settings (if needed)
# proxy:
#   http_proxy: "http://your-proxy.com:port"
#   https_proxy: "http://your-proxy.com:port"